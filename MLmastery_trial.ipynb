{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLmastery_trial",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMUzlyWJqVosqYI79TTbLV2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChathKSA/training/blob/main/MLmastery_trial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSr_4QeWarw7"
      },
      "source": [
        "#4. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9flnyRUFNys"
      },
      "source": [
        "# load dataset\n",
        "from pandas import read_csv\n",
        " \n",
        "# load a single file as a numpy array\n",
        "def load_file(filepath):\n",
        "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
        "\treturn dataframe.values\n",
        " \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "L0Zr7R7jKcmn",
        "outputId": "a3d3f8bb-bb3c-43e0-b49c-81fe9dc5b1f8"
      },
      "source": [
        "data = load_file('HARDataset/train/Inertial Signals/total_acc_y_train.txt')\n",
        "print(data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-12853893eb52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HARDataset/train/Inertial Signals/total_acc_y_train.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-70000005bcd1>\u001b[0m in \u001b[0;36mload_file\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# load a single file as a numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelim_whitespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'HARDataset/train/Inertial Signals/total_acc_y_train.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Za5H-BaQGWNa"
      },
      "source": [
        "data = load_file('HARDataset/train/Inertial Signals/total_acc_x_train.txt')\n",
        "print(data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR2r2zxsZ5bl"
      },
      "source": [
        "\n",
        "# load dataset\n",
        "from numpy import dstack\n",
        "from pandas import read_csv\n",
        "\n",
        "# load a single file as a numpy array\n",
        "def load_file(filepath):\n",
        "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
        "\treturn dataframe.values\n",
        "\n",
        "# load a list of files, such as x, y, z data for a given variable\n",
        "def load_group(filenames, prefix=''):\n",
        "\tloaded = list()\n",
        "\tfor name in filenames:\n",
        "\t\tdata = load_file(prefix + name)\n",
        "\t\tloaded.append(data)\n",
        "\t# stack group so that features are the 3rd dimension\n",
        "\tloaded = dstack(loaded)\n",
        "\treturn loaded\n",
        "\n",
        "# load the total acc data\n",
        "filenames = ['total_acc_x_train.txt', 'total_acc_y_train.txt', 'total_acc_z_train.txt']\n",
        "total_acc = load_group(filenames, prefix='HARDataset/train/Inertial Signals/')\n",
        "print(total_acc.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caGRb_iUaF8T"
      },
      "source": [
        "# load dataset\n",
        "from numpy import dstack\n",
        "from pandas import read_csv\n",
        " \n",
        "# load a single file as a numpy array\n",
        "def load_file(filepath):\n",
        "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
        "\treturn dataframe.values\n",
        " \n",
        "# load a list of files, such as x, y, z data for a given variable\n",
        "def load_group(filenames, prefix=''):\n",
        "\tloaded = list()\n",
        "\tfor name in filenames:\n",
        "\t\tdata = load_file(prefix + name)\n",
        "\t\tloaded.append(data)\n",
        "\t# stack group so that features are the 3rd dimension\n",
        "\tloaded = dstack(loaded)\n",
        "\treturn loaded\n",
        " \n",
        "# load a dataset group, such as train or test\n",
        "def load_dataset(group, prefix=''):\n",
        "\tfilepath = prefix + group + '/Inertial Signals/'\n",
        "\t# load all 9 files as a single array\n",
        "\tfilenames = list()\n",
        "\t# total acceleration\n",
        "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
        "\t# body acceleration\n",
        "\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
        "\t# body gyroscope\n",
        "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
        "\t# load input data\n",
        "\tX = load_group(filenames, filepath)\n",
        "\t# load class output\n",
        "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n",
        "\treturn X, y\n",
        " \n",
        "# load all train\n",
        "trainX, trainy = load_dataset('train', 'HARDataset/')\n",
        "print(trainX.shape, trainy.shape)\n",
        "# load all test\n",
        "testX, testy = load_dataset('test', 'HARDataset/')\n",
        "print(testX.shape, testy.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEGMrzxhaiKD"
      },
      "source": [
        "#5. Balance of Activity Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nksfAKCIah3M"
      },
      "source": [
        "# summarize class balance\n",
        "from numpy import array\n",
        "from numpy import vstack\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        " \n",
        "# load a single file as a numpy array\n",
        "def load_file(filepath):\n",
        "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
        "\treturn dataframe.values\n",
        " \n",
        "# summarize the balance of classes in an output variable column\n",
        "def class_breakdown(data):\n",
        "\t# convert the numpy array into a dataframe\n",
        "\tdf = DataFrame(data)\n",
        "\t# group data by the class value and calculate the number of rows\n",
        "\tcounts = df.groupby(0).size()\n",
        "\t# retrieve raw rows\n",
        "\tcounts = counts.values\n",
        "\t# summarize\n",
        "\tfor i in range(len(counts)):\n",
        "\t\tpercent = counts[i] / len(df) * 100\n",
        "\t\tprint('Class=%d, total=%d, percentage=%.3f' % (i+1, counts[i], percent))\n",
        " \n",
        "# load train file\n",
        "trainy = load_file('HARDataset/train/y_train.txt')\n",
        "# summarize class breakdown\n",
        "print('Train Dataset')\n",
        "class_breakdown(trainy)\n",
        " \n",
        "# load test file\n",
        "testy = load_file('HARDataset/test/y_test.txt')\n",
        "# summarize class breakdown\n",
        "print('Test Dataset')\n",
        "class_breakdown(testy)\n",
        " \n",
        "# summarize combined class breakdown\n",
        "print('Both')\n",
        "combined = vstack((trainy, testy))\n",
        "class_breakdown(combined)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHohYJb5cZVr"
      },
      "source": [
        "#6. Plot Time Series Data for One Subject"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJPk9arrcbPZ"
      },
      "source": [
        "# load data\n",
        "trainX, trainy = load_dataset('train', 'HARDataset/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W01DkSdQckqC"
      },
      "source": [
        "import numpy as np \n",
        "sub_map = load_file('HARDataset/train/subject_train.txt')\n",
        "train_subjects = np.unique(sub_map)\n",
        "print(train_subjects)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci_CfZx9f8eH"
      },
      "source": [
        "# get all data for one subject\n",
        "def data_for_subject(X, y, sub_map, sub_id):\n",
        "\t# get row indexes for the subject id\n",
        "\tix = [i for i in range(len(sub_map)) if sub_map[i]==sub_id]\n",
        "\t# return the selected samples\n",
        "\treturn X[ix, :, :], y[ix]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3bKVPgIf-dM"
      },
      "source": [
        "# convert a series of windows to a 1D list\n",
        "def to_series(windows):\n",
        "\tseries = list()\n",
        "\tfor window in windows:\n",
        "\t\t# remove the overlap from the window\n",
        "\t\thalf = int(len(window) / 2) - 1\n",
        "\t\tfor value in window[-half:]:\n",
        "\t\t\tseries.append(value)\n",
        "\treturn series"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir__7ahGgFZQ"
      },
      "source": [
        "# plot the data for one subject\n",
        "def plot_subject(X, y):\n",
        "\tpyplot.figure()\n",
        "\t# determine the total number of plots\n",
        "\tn, off = X.shape[2] + 1, 0\n",
        "\t# plot total acc\n",
        "\tfor i in range(3):\n",
        "\t\tpyplot.subplot(n, 1, off+1)\n",
        "\t\tpyplot.plot(to_series(X[:, :, off]))\n",
        "\t\tpyplot.title('total acc '+str(i), y=0, loc='left')\n",
        "\t\toff += 1\n",
        "\t# plot body acc\n",
        "\tfor i in range(3):\n",
        "\t\tpyplot.subplot(n, 1, off+1)\n",
        "\t\tpyplot.plot(to_series(X[:, :, off]))\n",
        "\t\tpyplot.title('body acc '+str(i), y=0, loc='left')\n",
        "\t\toff += 1\n",
        "\t# plot body gyro\n",
        "\tfor i in range(3):\n",
        "\t\tpyplot.subplot(n, 1, off+1)\n",
        "\t\tpyplot.plot(to_series(X[:, :, off]))\n",
        "\t\tpyplot.title('body gyro '+str(i), y=0, loc='left')\n",
        "\t\toff += 1\n",
        "\t# plot activities\n",
        "\tpyplot.subplot(n, 1, n)\n",
        "\tpyplot.plot(y)\n",
        "\tpyplot.title('activity', y=0, loc='left')\n",
        "\tpyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhOmd5X-gJXw"
      },
      "source": [
        "all in one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlOvyXz5gLEw"
      },
      "source": [
        "# plot all vars for one subject\n",
        "from numpy import array\n",
        "from numpy import dstack\n",
        "from numpy import unique\n",
        "from pandas import read_csv\n",
        "from matplotlib import pyplot\n",
        " \n",
        "# load a single file as a numpy array\n",
        "def load_file(filepath):\n",
        "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
        "\treturn dataframe.values\n",
        " \n",
        "# load a list of files, such as x, y, z data for a given variable\n",
        "def load_group(filenames, prefix=''):\n",
        "\tloaded = list()\n",
        "\tfor name in filenames:\n",
        "\t\tdata = load_file(prefix + name)\n",
        "\t\tloaded.append(data)\n",
        "\t# stack group so that features are the 3rd dimension\n",
        "\tloaded = dstack(loaded)\n",
        "\treturn loaded\n",
        " \n",
        "# load a dataset group, such as train or test\n",
        "def load_dataset(group, prefix=''):\n",
        "\tfilepath = prefix + group + '/Inertial Signals/'\n",
        "\t# load all 9 files as a single array\n",
        "\tfilenames = list()\n",
        "\t# total acceleration\n",
        "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
        "\t# body acceleration\n",
        "\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
        "\t# body gyroscope\n",
        "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
        "\t# load input data\n",
        "\tX = load_group(filenames, filepath)\n",
        "\t# load class output\n",
        "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n",
        "\treturn X, y\n",
        " \n",
        "# get all data for one subject\n",
        "def data_for_subject(X, y, sub_map, sub_id):\n",
        "\t# get row indexes for the subject id\n",
        "\tix = [i for i in range(len(sub_map)) if sub_map[i]==sub_id]\n",
        "\t# return the selected samples\n",
        "\treturn X[ix, :, :], y[ix]\n",
        " \n",
        "# convert a series of windows to a 1D list\n",
        "def to_series(windows):\n",
        "\tseries = list()\n",
        "\tfor window in windows:\n",
        "\t\t# remove the overlap from the window\n",
        "\t\thalf = int(len(window) / 2) - 1\n",
        "\t\tfor value in window[-half:]:\n",
        "\t\t\tseries.append(value)\n",
        "\treturn series\n",
        " \n",
        "# plot the data for one subject\n",
        "def plot_subject(X, y):\n",
        "\tpyplot.figure()\n",
        "\t# determine the total number of plots\n",
        "\tn, off = X.shape[2] + 1, 0\n",
        "\t# plot total acc\n",
        "\tfor i in range(3):\n",
        "\t\tpyplot.subplot(n, 1, off+1)\n",
        "\t\tpyplot.plot(to_series(X[:, :, off]))\n",
        "\t\tpyplot.title('total acc '+str(i), y=0, loc='left')\n",
        "\t\toff += 1\n",
        "\t# plot body acc\n",
        "\tfor i in range(3):\n",
        "\t\tpyplot.subplot(n, 1, off+1)\n",
        "\t\tpyplot.plot(to_series(X[:, :, off]))\n",
        "\t\tpyplot.title('body acc '+str(i), y=0, loc='left')\n",
        "\t\toff += 1\n",
        "\t# plot body gyro\n",
        "\tfor i in range(3):\n",
        "\t\tpyplot.subplot(n, 1, off+1)\n",
        "\t\tpyplot.plot(to_series(X[:, :, off]))\n",
        "\t\tpyplot.title('body gyro '+str(i), y=0, loc='left')\n",
        "\t\toff += 1\n",
        "\t# plot activities\n",
        "\tpyplot.subplot(n, 1, n)\n",
        "\tpyplot.plot(y)\n",
        "\tpyplot.title('activity', y=0, loc='left')\n",
        "\tpyplot.show()\n",
        " \n",
        "# load data\n",
        "trainX, trainy = load_dataset('train', 'HARDataset/')\n",
        "# load mapping of rows to subjects\n",
        "sub_map = load_file('HARDataset/train/subject_train.txt')\n",
        "train_subjects = unique(sub_map)\n",
        "print(train_subjects)\n",
        "# get the data for one subject\n",
        "sub_id = train_subjects[0]\n",
        "subX, suby = data_for_subject(trainX, trainy, sub_map, sub_id)\n",
        "print(subX.shape, suby.shape)\n",
        "# plot data for subject\n",
        "plot_subject(subX, suby)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umtOrOGbgQSn"
      },
      "source": [
        "\n",
        "# get the data for one subject\n",
        "sub_id = train_subjects[1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUptqekVgXy2"
      },
      "source": [
        "#7. Plot Histograms Per Subject"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W_RQSihgY9C"
      },
      "source": [
        "# plot histograms for multiple subjects\n",
        "from numpy import array\n",
        "from numpy import unique\n",
        "from numpy import dstack\n",
        "from pandas import read_csv\n",
        "from matplotlib import pyplot\n",
        " \n",
        "# load a single file as a numpy array\n",
        "def load_file(filepath):\n",
        "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
        "\treturn dataframe.values\n",
        " \n",
        "# load a list of files, such as x, y, z data for a given variable\n",
        "def load_group(filenames, prefix=''):\n",
        "\tloaded = list()\n",
        "\tfor name in filenames:\n",
        "\t\tdata = load_file(prefix + name)\n",
        "\t\tloaded.append(data)\n",
        "\t# stack group so that features are the 3rd dimension\n",
        "\tloaded = dstack(loaded)\n",
        "\treturn loaded\n",
        " \n",
        "# load a dataset group, such as train or test\n",
        "def load_dataset(group, prefix=''):\n",
        "\tfilepath = prefix + group + '/Inertial Signals/'\n",
        "\t# load all 9 files as a single array\n",
        "\tfilenames = list()\n",
        "\t# total acceleration\n",
        "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
        "\t# body acceleration\n",
        "\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
        "\t# body gyroscope\n",
        "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
        "\t# load input data\n",
        "\tX = load_group(filenames, filepath)\n",
        "\t# load class output\n",
        "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n",
        "\treturn X, y\n",
        " \n",
        "# get all data for one subject\n",
        "def data_for_subject(X, y, sub_map, sub_id):\n",
        "\t# get row indexes for the subject id\n",
        "\tix = [i for i in range(len(sub_map)) if sub_map[i]==sub_id]\n",
        "\t# return the selected samples\n",
        "\treturn X[ix, :, :], y[ix]\n",
        " \n",
        "# convert a series of windows to a 1D list\n",
        "def to_series(windows):\n",
        "\tseries = list()\n",
        "\tfor window in windows:\n",
        "\t\t# remove the overlap from the window\n",
        "\t\thalf = int(len(window) / 2) - 1\n",
        "\t\tfor value in window[-half:]:\n",
        "\t\t\tseries.append(value)\n",
        "\treturn series\n",
        " \n",
        "# plot histograms for multiple subjects\n",
        "def plot_subject_histograms(X, y, sub_map, n=10):\n",
        "\tpyplot.figure()\n",
        "\t# get unique subjects\n",
        "\tsubject_ids = unique(sub_map[:,0])\n",
        "\t# enumerate subjects\n",
        "\txaxis = None\n",
        "\tfor k in range(n):\n",
        "\t\tsub_id = subject_ids[k]\n",
        "\t\t# get data for one subject\n",
        "\t\tsubX, _ = data_for_subject(X, y, sub_map, sub_id)\n",
        "\t\t# total acc\n",
        "\t\tfor i in range(3):\n",
        "\t\t\tax = pyplot.subplot(n, 1, k+1, sharex=xaxis)\n",
        "\t\t\tax.set_xlim(-1,1)\n",
        "\t\t\tif k == 0:\n",
        "\t\t\t\txaxis = ax\n",
        "\t\t\tpyplot.hist(to_series(subX[:,:,i]), bins=100)\n",
        "\tpyplot.show()\n",
        " \n",
        "# load training dataset\n",
        "X, y = load_dataset('train', 'HARDataset/')\n",
        "# load mapping of rows to subjects\n",
        "sub_map = load_file('HARDataset/train/subject_train.txt')\n",
        "# plot histograms for subjects\n",
        "plot_subject_histograms(X, y, sub_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bXhHVFOggmH"
      },
      "source": [
        "# plot histograms for multiple subjects\n",
        "def plot_subject_histograms(X, y, sub_map, n=10):\n",
        "\tpyplot.figure()\n",
        "\t# get unique subjects\n",
        "\tsubject_ids = unique(sub_map[:,0])\n",
        "\t# enumerate subjects\n",
        "\txaxis = None\n",
        "\tfor k in range(n):\n",
        "\t\tsub_id = subject_ids[k]\n",
        "\t\t# get data for one subject\n",
        "\t\tsubX, _ = data_for_subject(X, y, sub_map, sub_id)\n",
        "\t\t# body acc\n",
        "\t\tfor i in range(3):\n",
        "\t\t\tax = pyplot.subplot(n, 1, k+1, sharex=xaxis)\n",
        "\t\t\tax.set_xlim(-1,1)\n",
        "\t\t\tif k == 0:\n",
        "\t\t\t\txaxis = ax\n",
        "\t\t\tpyplot.hist(to_series(subX[:,:,3+i]), bins=100)\n",
        "\tpyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vvk9I8omgjln"
      },
      "source": [
        "# plot histograms for multiple subjects\n",
        "def plot_subject_histograms(X, y, sub_map, n=10):\n",
        "\tpyplot.figure()\n",
        "\t# get unique subjects\n",
        "\tsubject_ids = unique(sub_map[:,0])\n",
        "\t# enumerate subjects\n",
        "\txaxis = None\n",
        "\tfor k in range(n):\n",
        "\t\tsub_id = subject_ids[k]\n",
        "\t\t# get data for one subject\n",
        "\t\tsubX, _ = data_for_subject(X, y, sub_map, sub_id)\n",
        "\t\t# body acc\n",
        "\t\tfor i in range(3):\n",
        "\t\t\tax = pyplot.subplot(n, 1, k+1, sharex=xaxis)\n",
        "\t\t\tax.set_xlim(-1,1)\n",
        "\t\t\tif k == 0:\n",
        "\t\t\t\txaxis = ax\n",
        "\t\t\tpyplot.hist(to_series(subX[:,:,6+i]), bins=100)\n",
        "\tpyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFU5LPCQgmYq"
      },
      "source": [
        "#8. Plot Histograms Per Activity\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmS5_vJVgnUe"
      },
      "source": [
        "# plot histograms per activity for a subject\n",
        "from numpy import array\n",
        "from numpy import dstack\n",
        "from numpy import unique\n",
        "from pandas import read_csv\n",
        "from matplotlib import pyplot\n",
        " \n",
        "# load a single file as a numpy array\n",
        "def load_file(filepath):\n",
        "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
        "\treturn dataframe.values\n",
        " \n",
        "# load a list of files, such as x, y, z data for a given variable\n",
        "def load_group(filenames, prefix=''):\n",
        "\tloaded = list()\n",
        "\tfor name in filenames:\n",
        "\t\tdata = load_file(prefix + name)\n",
        "\t\tloaded.append(data)\n",
        "\t# stack group so that features are the 3rd dimension\n",
        "\tloaded = dstack(loaded)\n",
        "\treturn loaded\n",
        " \n",
        "# load a dataset group, such as train or test\n",
        "def load_dataset(group, prefix=''):\n",
        "\tfilepath = prefix + group + '/Inertial Signals/'\n",
        "\t# load all 9 files as a single array\n",
        "\tfilenames = list()\n",
        "\t# total acceleration\n",
        "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
        "\t# body acceleration\n",
        "\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
        "\t# body gyroscope\n",
        "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
        "\t# load input data\n",
        "\tX = load_group(filenames, filepath)\n",
        "\t# load class output\n",
        "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n",
        "\treturn X, y\n",
        " \n",
        "# get all data for one subject\n",
        "def data_for_subject(X, y, sub_map, sub_id):\n",
        "\t# get row indexes for the subject id\n",
        "\tix = [i for i in range(len(sub_map)) if sub_map[i]==sub_id]\n",
        "\t# return the selected samples\n",
        "\treturn X[ix, :, :], y[ix]\n",
        " \n",
        "# convert a series of windows to a 1D list\n",
        "def to_series(windows):\n",
        "\tseries = list()\n",
        "\tfor window in windows:\n",
        "\t\t# remove the overlap from the window\n",
        "\t\thalf = int(len(window) / 2) - 1\n",
        "\t\tfor value in window[-half:]:\n",
        "\t\t\tseries.append(value)\n",
        "\treturn series\n",
        " \n",
        "# group data by activity\n",
        "def data_by_activity(X, y, activities):\n",
        "\t# group windows by activity\n",
        "\treturn {a:X[y[:,0]==a, :, :] for a in activities}\n",
        " \n",
        "# plot histograms for each activity for a subject\n",
        "def plot_activity_histograms(X, y):\n",
        "\t# get a list of unique activities for the subject\n",
        "\tactivity_ids = unique(y[:,0])\n",
        "\t# group windows by activity\n",
        "\tgrouped = data_by_activity(X, y, activity_ids)\n",
        "\t# plot per activity, histograms for each axis\n",
        "\tpyplot.figure()\n",
        "\txaxis = None\n",
        "\tfor k in range(len(activity_ids)):\n",
        "\t\tact_id = activity_ids[k]\n",
        "\t\t# total acceleration\n",
        "\t\tfor i in range(3):\n",
        "\t\t\tax = pyplot.subplot(len(activity_ids), 1, k+1, sharex=xaxis)\n",
        "\t\t\tax.set_xlim(-1,1)\n",
        "\t\t\tif k == 0:\n",
        "\t\t\t\txaxis = ax\n",
        "\t\t\tpyplot.hist(to_series(grouped[act_id][:,:,i]), bins=100)\n",
        "\t\t\tpyplot.title('activity '+str(act_id), y=0, loc='left')\n",
        "\tpyplot.show()\n",
        " \n",
        "# load data\n",
        "trainX, trainy = load_dataset('train', 'HARDataset/')\n",
        "# load mapping of rows to subjects\n",
        "sub_map = load_file('HARDataset/train/subject_train.txt')\n",
        "train_subjects = unique(sub_map)\n",
        "# get the data for one subject\n",
        "sub_id = train_subjects[0]\n",
        "subX, suby = data_for_subject(trainX, trainy, sub_map, sub_id)\n",
        "# plot data for subject\n",
        "plot_activity_histograms(subX, suby)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2a7lGP-guXJ"
      },
      "source": [
        "# plot histograms for each activity for a subject\n",
        "def plot_activity_histograms(X, y):\n",
        "\t# get a list of unique activities for the subject\n",
        "\tactivity_ids = unique(y[:,0])\n",
        "\t# group windows by activity\n",
        "\tgrouped = data_by_activity(X, y, activity_ids)\n",
        "\t# plot per activity, histograms for each axis\n",
        "\tpyplot.figure()\n",
        "\txaxis = None\n",
        "\tfor k in range(len(activity_ids)):\n",
        "\t\tact_id = activity_ids[k]\n",
        "\t\t# total acceleration\n",
        "\t\tfor i in range(3):\n",
        "\t\t\tax = pyplot.subplot(len(activity_ids), 1, k+1, sharex=xaxis)\n",
        "\t\t\tax.set_xlim(-1,1)\n",
        "\t\t\tif k == 0:\n",
        "\t\t\t\txaxis = ax\n",
        "\t\t\tpyplot.hist(to_series(grouped[act_id][:,:,3+i]), bins=100)\n",
        "\t\t\tpyplot.title('activity '+str(act_id), y=0, loc='left')\n",
        "\tpyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBU7Zi_qgxFA"
      },
      "source": [
        "# plot histograms for each activity for a subject\n",
        "def plot_activity_histograms(X, y):\n",
        "\t# get a list of unique activities for the subject\n",
        "\tactivity_ids = unique(y[:,0])\n",
        "\t# group windows by activity\n",
        "\tgrouped = data_by_activity(X, y, activity_ids)\n",
        "\t# plot per activity, histograms for each axis\n",
        "\tpyplot.figure()\n",
        "\txaxis = None\n",
        "\tfor k in range(len(activity_ids)):\n",
        "\t\tact_id = activity_ids[k]\n",
        "\t\t# total acceleration\n",
        "\t\tfor i in range(3):\n",
        "\t\t\tax = pyplot.subplot(len(activity_ids), 1, k+1, sharex=xaxis)\n",
        "\t\t\tax.set_xlim(-1,1)\n",
        "\t\t\tif k == 0:\n",
        "\t\t\t\txaxis = ax\n",
        "\t\t\tpyplot.hist(to_series(grouped[act_id][:,:,6+i]), bins=100)\n",
        "\t\t\tpyplot.title('activity '+str(act_id), y=0, loc='left')\n",
        "\tpyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FISR_HMTgyto"
      },
      "source": [
        "#9. Plot Activity Duration Boxplots\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avliznqTgzpr"
      },
      "source": [
        "# plot durations of each activity by subject\n",
        "from numpy import array\n",
        "from numpy import dstack\n",
        "from numpy import unique\n",
        "from pandas import read_csv\n",
        "from matplotlib import pyplot\n",
        " \n",
        "# load a single file as a numpy array\n",
        "def load_file(filepath):\n",
        "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
        "\treturn dataframe.values\n",
        " \n",
        "# load a list of files, such as x, y, z data for a given variable\n",
        "def load_group(filenames, prefix=''):\n",
        "\tloaded = list()\n",
        "\tfor name in filenames:\n",
        "\t\tdata = load_file(prefix + name)\n",
        "\t\tloaded.append(data)\n",
        "\t# stack group so that features are the 3rd dimension\n",
        "\tloaded = dstack(loaded)\n",
        "\treturn loaded\n",
        " \n",
        "# load a dataset group, such as train or test\n",
        "def load_dataset(group, prefix=''):\n",
        "\tfilepath = prefix + group + '/Inertial Signals/'\n",
        "\t# load all 9 files as a single array\n",
        "\tfilenames = list()\n",
        "\t# total acceleration\n",
        "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
        "\t# body acceleration\n",
        "\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
        "\t# body gyroscope\n",
        "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
        "\t# load input data\n",
        "\tX = load_group(filenames, filepath)\n",
        "\t# load class output\n",
        "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n",
        "\treturn X, y\n",
        " \n",
        "# get all data for one subject\n",
        "def data_for_subject(X, y, sub_map, sub_id):\n",
        "\t# get row indexes for the subject id\n",
        "\tix = [i for i in range(len(sub_map)) if sub_map[i]==sub_id]\n",
        "\t# return the selected samples\n",
        "\treturn X[ix, :, :], y[ix]\n",
        " \n",
        "# convert a series of windows to a 1D list\n",
        "def to_series(windows):\n",
        "\tseries = list()\n",
        "\tfor window in windows:\n",
        "\t\t# remove the overlap from the window\n",
        "\t\thalf = int(len(window) / 2) - 1\n",
        "\t\tfor value in window[-half:]:\n",
        "\t\t\tseries.append(value)\n",
        "\treturn series\n",
        " \n",
        "# group data by activity\n",
        "def data_by_activity(X, y, activities):\n",
        "\t# group windows by activity\n",
        "\treturn {a:X[y[:,0]==a, :, :] for a in activities}\n",
        " \n",
        "# plot activity durations by subject\n",
        "def plot_activity_durations_by_subject(X, y, sub_map):\n",
        "\t# get unique subjects and activities\n",
        "\tsubject_ids = unique(sub_map[:,0])\n",
        "\tactivity_ids = unique(y[:,0])\n",
        "\t# enumerate subjects\n",
        "\tactivity_windows = {a:list() for a in activity_ids}\n",
        "\tfor sub_id in subject_ids:\n",
        "\t\t# get data for one subject\n",
        "\t\t_, subj_y = data_for_subject(X, y, sub_map, sub_id)\n",
        "\t\t# count windows by activity\n",
        "\t\tfor a in activity_ids:\n",
        "\t\t\tactivity_windows[a].append(len(subj_y[subj_y[:,0]==a]))\n",
        "\t# organize durations into a list of lists\n",
        "\tdurations = [activity_windows[a] for a in activity_ids]\n",
        "\tpyplot.boxplot(durations, labels=activity_ids)\n",
        "\tpyplot.show()\n",
        " \n",
        "# load training dataset\n",
        "X, y = load_dataset('train', 'HARDataset/')\n",
        "# load mapping of rows to subjects\n",
        "sub_map = load_file('HARDataset/train/subject_train.txt')\n",
        "# plot durations\n",
        "plot_activity_durations_by_subject(X, y, sub_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpS0GqMFg41L"
      },
      "source": [
        "# load test dataset\n",
        "X, y = load_dataset('test', 'HARDataset/')\n",
        "# load mapping of rows to subjects\n",
        "sub_map = load_file('HARDataset/test/subject_test.txt')\n",
        "# plot durations\n",
        "plot_activity_durations_by_subject(X, y, sub_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24cdSElhg67M"
      },
      "source": [
        "#10. Approach to Modeling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGOZALAxg7yw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}